{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab0f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is: 2.6.0\n",
      "Eager execution is: True\n",
      "Keras version is: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import io\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, MaxPool2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "\n",
    "print(\"TensorFlow version is: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version is: {}\".format(tf.keras.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a04562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define YOLOv4 newly added activation function MISH\n",
    "class Mish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'mish'\n",
    "\n",
    "\n",
    "def mysoftplus(x):\n",
    "\n",
    "    mask_min = tf.cast((x<-20.0),tf.float32)\n",
    "    ymin = mask_min*tf.math.exp(x)\n",
    "\n",
    "    mask_max = tf.cast((x>20.0),tf.float32)\n",
    "    ymax = mask_max*x\n",
    "    \n",
    "    mask= tf.cast((abs(x)<=20.0),tf.float32)\n",
    "    y = mask*tf.math.log(tf.math.exp(x) + 1.0)\n",
    "    \n",
    "    return(ymin+ymax+y)    \n",
    "        \n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return (x* tf.math.tanh(mysoftplus(x)))\n",
    "    \n",
    "\n",
    "get_custom_objects().update({'mish': Mish(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8637642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding Mish activation function in convolution layer \n",
    "def _conv_block(inp, convs, skip=False):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)), name='zerop_' + str(conv['layer_idx']))(x)  # peculiar padding as darknet prefer left and top\n",
    "        \n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='convn_' + str(conv['layer_idx']) if conv['bnorm'] else 'conv_' + str(conv['layer_idx']),\n",
    "                   activation='mish' if conv['activ'] == 2 else None,\n",
    "                   use_bias=True)(x)\n",
    "                  \n",
    "        if conv['activ'] == 1: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "            \n",
    "    return add([skip_connection, x],  name='add_' + str(conv['layer_idx']+1)) if skip else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c9bfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define YOLOv4 architecture\n",
    "def make_yolov4_model():\n",
    "        \n",
    "    input_image = Input(shape=(608, 608, 3), name='input_0')\n",
    "\n",
    "    # Layer  0\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 0}])\n",
    "    layer_0 = x\n",
    "    # Layer  1\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 1}])\n",
    "    layer_1 = x\n",
    "    \n",
    "    # Layer  2 \n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 2}])\n",
    "    layer_2 = x\n",
    "    \n",
    "    # route  1 (layers = -2)\n",
    "    x = layer_1\n",
    "    # Layer  3 => 5\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 4},\n",
    "                        {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 5},\n",
    "                        {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 6}],\n",
    "                   skip = True)\n",
    "\n",
    "    # Layer  8 => 8\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 8}])\n",
    "    layer_8 = x\n",
    "    \n",
    "    # route  8+2 (layers = -1, -7)\n",
    "    x = concatenate([layer_8, layer_2], name='concat_9')\n",
    "    \n",
    "    # Layer 10 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 10},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 11}])\n",
    "    layer_11 = x\n",
    "    \n",
    "    # Layer  12\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 12}])\n",
    "    layer_12 = x\n",
    "    \n",
    "    # route  11 (layers = -2)\n",
    "    x = layer_11\n",
    "    # Layer 14 => 16\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 14},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 15},\n",
    "                        {'filter':  64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 16}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer 18 => 19\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 18},\n",
    "                        {'filter':  64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 19}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer  21\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 21}]) \n",
    "    layer_21 = x\n",
    "    \n",
    "    # route  21+12 (layers = -1,-10)\n",
    "    x = concatenate([layer_21, layer_12], name='concat_22')\n",
    "    \n",
    "    # Layer 23 => 24\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 23},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 24}])\n",
    "    layer_24 = x\n",
    "    \n",
    "    # Layer  25\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 25}])\n",
    "    layer_25 = x\n",
    "    \n",
    "    # route  24 (layers = -2)\n",
    "    x = layer_24\n",
    "    \n",
    "    # Layer 27 => 29\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 27},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 28},\n",
    "                        {'filter':  128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 29}],\n",
    "                   skip = True)\n",
    "    \n",
    "    # Layer 31 => 50\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 31+(i*3)},\n",
    "                            {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 32+(i*3)}],\n",
    "                       skip = True)\n",
    "  \n",
    "    # Layer  52\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 52}])\n",
    "    layer_52 = x\n",
    "        \n",
    "    # route  52+25 (layers = -1,-28)\n",
    "    x = concatenate([layer_52, layer_25],  name='concat_53')\n",
    "    \n",
    "    # Layer 54\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 54}])\n",
    "    layer_54 = x\n",
    "    \n",
    "    # Layer  55\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 55}])\n",
    "    layer_55 = x\n",
    "    \n",
    "    # Layer  56\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 56}])\n",
    "    layer_56 = x\n",
    "    \n",
    "    # route  55 (layers = -2)\n",
    "    x = layer_55\n",
    "    \n",
    "    # Layer 58 => 60\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 58},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 59},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 60}],\n",
    "                   skip = True)     \n",
    "\n",
    "    # Layer 62 => 81\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 62+(i*3)},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 63+(i*3)}],\n",
    "                       skip = True)\n",
    "\n",
    "    # Layer  83\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 83}])\n",
    "    layer_83 = x\n",
    "\n",
    "    # route  83+56 (layers = -1,-28)\n",
    "    x = concatenate([layer_83, layer_56], name='concat_84')\n",
    "    \n",
    "    # Layer 85\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 85}])\n",
    "    layer_85 = x\n",
    "    \n",
    "    # Layer  86\n",
    "    x = _conv_block(x, [{'filter':  1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 2, 'layer_idx': 86}])\n",
    "    layer_86 = x\n",
    "    \n",
    "    # Layer  87\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 87}])\n",
    "    layer_87 = x\n",
    "        \n",
    "    # route  86 (layers = -2)\n",
    "    x = layer_86\n",
    "    \n",
    "    # Layer 89 => 92\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 89},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 90},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 91}],\n",
    "                   skip = True) \n",
    "    \n",
    "    \n",
    "    # Layer 93 => 100\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter': 512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 93+(i*3)},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 94+(i*3)}],\n",
    "                       skip = True)  \n",
    "    \n",
    "    \n",
    "    # Layer  102 => 102\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 102}])  \n",
    "    layer_102 = x\n",
    "    \n",
    "    # route  102+87 (layers = -1,-16)\n",
    "    x = concatenate([layer_102, layer_87], name='concat_103')\n",
    "    \n",
    "    # Layer 104 => 107\n",
    "    x = _conv_block(x, [{'filter':  1024, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 2, 'layer_idx': 104},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 105},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 106},                        \n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 107}])\n",
    "    \n",
    "    #-- begin SPP part (Spatial Pyramid Pooling layer)\n",
    "    layer_107 = x\n",
    "    \n",
    "    # Layer 108\n",
    "    x =MaxPool2D(pool_size=(5, 5), strides=1, padding='same', name = 'layer_108')(x)  \n",
    "    layer_108 = x\n",
    "    \n",
    "    # route  107 (layers = -2)\n",
    "    x = layer_107\n",
    "    \n",
    "    # Layer 110\n",
    "    x =MaxPool2D(pool_size=(9, 9), strides=1, padding='same', name = 'layer_110')(x)    \n",
    "    layer_110 = x\n",
    "    \n",
    "    # route  107 (layers = -4)\n",
    "    x = layer_107\n",
    "        \n",
    "    # Layer 112\n",
    "    x =MaxPool2D(pool_size=(13, 13), strides=1, padding='same', name = 'layer_112')(x) \n",
    "    layer_112 = x\n",
    "    \n",
    "    # route  112+110+108+107 (layers=-1,-3,-5,-6)\n",
    "    x = concatenate([layer_112, layer_110, layer_108, layer_107], name='concat_113')\n",
    "    #-- end SPP part\n",
    "    \n",
    "    layer_113 = x\n",
    "    \n",
    "    # Layer 114 => 116\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 114},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 115},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 116}])\n",
    "    layer_116 = x\n",
    "                        \n",
    "    # Layer 117                    \n",
    "    x = _conv_block(x, [{'filter':   256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 117}])\n",
    "    layer_117 = x\n",
    "    # Layer 118\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_118')(x)\n",
    "    layer_118 = x\n",
    "                        \n",
    "    # route  85 (layers = 85)\n",
    "    x = layer_85\n",
    "    \n",
    "    # Layer 120\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 120}])\n",
    "    layer_120 = x\n",
    "                        \n",
    "    # route  120+118 (layers = -1, -3)\n",
    "    x = concatenate([layer_120, layer_118],  name='concat_121')\n",
    "    layer_121 = x                    \n",
    "    # Layer 122 => 126\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 122},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 123},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 124},  \n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 125},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 126}])\n",
    "    layer_126 = x \n",
    "                        \n",
    "    # Layer 127                    \n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 127}])\n",
    "    layer_127 = x\n",
    "    # Layer 128\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_128')(x)\n",
    "    layer_128 = x\n",
    "                        \n",
    "    # route  54 (layers = 54)\n",
    "    x = layer_54\n",
    "    \n",
    "    # Layer 130\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 130}])\n",
    "    layer_130 = x\n",
    "                        \n",
    "    # route  130+128 (layers = -1, -3)                 \n",
    "    x = concatenate([layer_130, layer_128],  name='concat_131')\n",
    "    layer_131 = x                    \n",
    "    # Layer 132 => 136\n",
    "    x = _conv_block(x, [{'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 132},\n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 133},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 134},  \n",
    "                        {'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 135},\n",
    "                        {'filter':  128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 136}])\n",
    "    layer_136 = x                   \n",
    "    \n",
    "    # Layer 137 => 138\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 137}]) \n",
    "    layer_137 = x \n",
    "    x = _conv_block(x, [{'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  0, 'layer_idx': 138}])   \n",
    "  \n",
    "    # Layer 139\n",
    "    yolo_139 = x\n",
    "                        \n",
    "    # route  136 (layers = -4)\n",
    "    x = layer_136\n",
    "    \n",
    "    # Layer 141\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 1, 'layer_idx': 141}])\n",
    "    layer_141 = x\n",
    "                        \n",
    "    # route  141+126 (layers = -1, -16)                   \n",
    "    x = concatenate([layer_141, layer_126],  name='concat_142')\n",
    "    \n",
    "    # Layer 143 => 147\n",
    "    x = _conv_block(x, [{'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 143},\n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 144},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 145},  \n",
    "                        {'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 146},\n",
    "                        {'filter':  256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':   1, 'layer_idx': 147}])  \n",
    "    layer_147 = x\n",
    "                        \n",
    "    # Layer 148 => 149                    \n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':  1, 'layer_idx': 148},\n",
    "                        {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':  0, 'layer_idx': 149}])\n",
    "                        \n",
    "    # Layer 150\n",
    "    yolo_150 = x                  \n",
    "    \n",
    "    # route  147 (layers = -4)\n",
    "    x = layer_147\n",
    "        \n",
    "    # Layer 152\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'activ': 1, 'layer_idx': 152}])\n",
    "    layer_152 = x  \n",
    "                        \n",
    "    # route  152+166 (layers = -1, -37)                   \n",
    "    x = concatenate([layer_152, layer_116],  name='concat_153') \n",
    "                        \n",
    "                        \n",
    "    # Layer 154 => 160\n",
    "    x = _conv_block(x, [{'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 154},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 155},\n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 156},\n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 157},  \n",
    "                        {'filter':   512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 158},   \n",
    "                        {'filter':  1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ':    1, 'layer_idx': 159},\n",
    "                        {'filter':   255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ':    0, 'layer_idx': 160}])  \n",
    "                     \n",
    "                        \n",
    "    # Layer 161\n",
    "    yolo_161 = x\n",
    "                        \n",
    "                        \n",
    "    model = Model(input_image, [yolo_139, yolo_150, yolo_161], name = 'Yolo_v4')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8d60a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = make_yolov4_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43302ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Yolo_v4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_0 (InputLayer)            [(None, 608, 608, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "convn_0 (Conv2D)                (None, 608, 608, 32) 896         input_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zerop_1 (ZeroPadding2D)         (None, 609, 609, 32) 0           convn_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_1 (Conv2D)                (None, 304, 304, 64) 18496       zerop_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_4 (Conv2D)                (None, 304, 304, 64) 4160        convn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_5 (Conv2D)                (None, 304, 304, 32) 2080        convn_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_6 (Conv2D)                (None, 304, 304, 64) 18496       convn_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 304, 304, 64) 0           convn_4[0][0]                    \n",
      "                                                                 convn_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_8 (Conv2D)                (None, 304, 304, 64) 4160        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "convn_2 (Conv2D)                (None, 304, 304, 64) 4160        convn_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_9 (Concatenate)          (None, 304, 304, 128 0           convn_8[0][0]                    \n",
      "                                                                 convn_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_10 (Conv2D)               (None, 304, 304, 64) 8256        concat_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zerop_11 (ZeroPadding2D)        (None, 305, 305, 64) 0           convn_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_11 (Conv2D)               (None, 152, 152, 128 73856       zerop_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_14 (Conv2D)               (None, 152, 152, 64) 8256        convn_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_15 (Conv2D)               (None, 152, 152, 64) 4160        convn_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_16 (Conv2D)               (None, 152, 152, 64) 36928       convn_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 152, 152, 64) 0           convn_14[0][0]                   \n",
      "                                                                 convn_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_18 (Conv2D)               (None, 152, 152, 64) 4160        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_19 (Conv2D)               (None, 152, 152, 64) 36928       convn_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 152, 152, 64) 0           add_17[0][0]                     \n",
      "                                                                 convn_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_21 (Conv2D)               (None, 152, 152, 64) 4160        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_12 (Conv2D)               (None, 152, 152, 64) 8256        convn_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_22 (Concatenate)         (None, 152, 152, 128 0           convn_21[0][0]                   \n",
      "                                                                 convn_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_23 (Conv2D)               (None, 152, 152, 128 16512       concat_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zerop_24 (ZeroPadding2D)        (None, 153, 153, 128 0           convn_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_24 (Conv2D)               (None, 76, 76, 256)  295168      zerop_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_27 (Conv2D)               (None, 76, 76, 128)  32896       convn_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_28 (Conv2D)               (None, 76, 76, 128)  16512       convn_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_29 (Conv2D)               (None, 76, 76, 128)  147584      convn_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 76, 76, 128)  0           convn_27[0][0]                   \n",
      "                                                                 convn_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_31 (Conv2D)               (None, 76, 76, 128)  16512       add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_32 (Conv2D)               (None, 76, 76, 128)  147584      convn_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 76, 76, 128)  0           add_30[0][0]                     \n",
      "                                                                 convn_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_34 (Conv2D)               (None, 76, 76, 128)  16512       add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_35 (Conv2D)               (None, 76, 76, 128)  147584      convn_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 76, 76, 128)  0           add_33[0][0]                     \n",
      "                                                                 convn_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_37 (Conv2D)               (None, 76, 76, 128)  16512       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_38 (Conv2D)               (None, 76, 76, 128)  147584      convn_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 76, 76, 128)  0           add_36[0][0]                     \n",
      "                                                                 convn_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_40 (Conv2D)               (None, 76, 76, 128)  16512       add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_41 (Conv2D)               (None, 76, 76, 128)  147584      convn_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 76, 76, 128)  0           add_39[0][0]                     \n",
      "                                                                 convn_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_43 (Conv2D)               (None, 76, 76, 128)  16512       add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_44 (Conv2D)               (None, 76, 76, 128)  147584      convn_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 76, 76, 128)  0           add_42[0][0]                     \n",
      "                                                                 convn_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_46 (Conv2D)               (None, 76, 76, 128)  16512       add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_47 (Conv2D)               (None, 76, 76, 128)  147584      convn_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 76, 76, 128)  0           add_45[0][0]                     \n",
      "                                                                 convn_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_49 (Conv2D)               (None, 76, 76, 128)  16512       add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_50 (Conv2D)               (None, 76, 76, 128)  147584      convn_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 76, 76, 128)  0           add_48[0][0]                     \n",
      "                                                                 convn_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_52 (Conv2D)               (None, 76, 76, 128)  16512       add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_25 (Conv2D)               (None, 76, 76, 128)  32896       convn_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_53 (Concatenate)         (None, 76, 76, 256)  0           convn_52[0][0]                   \n",
      "                                                                 convn_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_54 (Conv2D)               (None, 76, 76, 256)  65792       concat_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zerop_55 (ZeroPadding2D)        (None, 77, 77, 256)  0           convn_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_55 (Conv2D)               (None, 38, 38, 512)  1180160     zerop_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_58 (Conv2D)               (None, 38, 38, 256)  131328      convn_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_59 (Conv2D)               (None, 38, 38, 256)  65792       convn_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_60 (Conv2D)               (None, 38, 38, 256)  590080      convn_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 38, 38, 256)  0           convn_58[0][0]                   \n",
      "                                                                 convn_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_62 (Conv2D)               (None, 38, 38, 256)  65792       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_63 (Conv2D)               (None, 38, 38, 256)  590080      convn_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 38, 38, 256)  0           add_61[0][0]                     \n",
      "                                                                 convn_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_65 (Conv2D)               (None, 38, 38, 256)  65792       add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_66 (Conv2D)               (None, 38, 38, 256)  590080      convn_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 38, 38, 256)  0           add_64[0][0]                     \n",
      "                                                                 convn_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_68 (Conv2D)               (None, 38, 38, 256)  65792       add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_69 (Conv2D)               (None, 38, 38, 256)  590080      convn_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 38, 38, 256)  0           add_67[0][0]                     \n",
      "                                                                 convn_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_71 (Conv2D)               (None, 38, 38, 256)  65792       add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_72 (Conv2D)               (None, 38, 38, 256)  590080      convn_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 38, 38, 256)  0           add_70[0][0]                     \n",
      "                                                                 convn_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_74 (Conv2D)               (None, 38, 38, 256)  65792       add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_75 (Conv2D)               (None, 38, 38, 256)  590080      convn_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 38, 38, 256)  0           add_73[0][0]                     \n",
      "                                                                 convn_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_77 (Conv2D)               (None, 38, 38, 256)  65792       add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_78 (Conv2D)               (None, 38, 38, 256)  590080      convn_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 38, 38, 256)  0           add_76[0][0]                     \n",
      "                                                                 convn_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_80 (Conv2D)               (None, 38, 38, 256)  65792       add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_81 (Conv2D)               (None, 38, 38, 256)  590080      convn_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 38, 38, 256)  0           add_79[0][0]                     \n",
      "                                                                 convn_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_83 (Conv2D)               (None, 38, 38, 256)  65792       add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_56 (Conv2D)               (None, 38, 38, 256)  131328      convn_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_84 (Concatenate)         (None, 38, 38, 512)  0           convn_83[0][0]                   \n",
      "                                                                 convn_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_85 (Conv2D)               (None, 38, 38, 512)  262656      concat_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zerop_86 (ZeroPadding2D)        (None, 39, 39, 512)  0           convn_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_86 (Conv2D)               (None, 19, 19, 1024) 4719616     zerop_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_89 (Conv2D)               (None, 19, 19, 512)  524800      convn_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_90 (Conv2D)               (None, 19, 19, 512)  262656      convn_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_91 (Conv2D)               (None, 19, 19, 512)  2359808     convn_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 19, 19, 512)  0           convn_89[0][0]                   \n",
      "                                                                 convn_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_93 (Conv2D)               (None, 19, 19, 512)  262656      add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_94 (Conv2D)               (None, 19, 19, 512)  2359808     convn_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 19, 19, 512)  0           add_92[0][0]                     \n",
      "                                                                 convn_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_96 (Conv2D)               (None, 19, 19, 512)  262656      add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_97 (Conv2D)               (None, 19, 19, 512)  2359808     convn_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 19, 19, 512)  0           add_95[0][0]                     \n",
      "                                                                 convn_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_99 (Conv2D)               (None, 19, 19, 512)  262656      add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convn_100 (Conv2D)              (None, 19, 19, 512)  2359808     convn_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 19, 19, 512)  0           add_98[0][0]                     \n",
      "                                                                 convn_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_102 (Conv2D)              (None, 19, 19, 512)  262656      add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convn_87 (Conv2D)               (None, 19, 19, 512)  524800      convn_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_103 (Concatenate)        (None, 19, 19, 1024) 0           convn_102[0][0]                  \n",
      "                                                                 convn_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convn_104 (Conv2D)              (None, 19, 19, 1024) 1049600     concat_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "convn_105 (Conv2D)              (None, 19, 19, 512)  524800      convn_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_105 (LeakyReLU)           (None, 19, 19, 512)  0           convn_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_106 (Conv2D)              (None, 19, 19, 1024) 4719616     leaky_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_106 (LeakyReLU)           (None, 19, 19, 1024) 0           convn_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convn_107 (Conv2D)              (None, 19, 19, 512)  524800      leaky_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_107 (LeakyReLU)           (None, 19, 19, 512)  0           convn_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_112 (MaxPooling2D)        (None, 19, 19, 512)  0           leaky_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_110 (MaxPooling2D)        (None, 19, 19, 512)  0           leaky_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_108 (MaxPooling2D)        (None, 19, 19, 512)  0           leaky_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_113 (Concatenate)        (None, 19, 19, 2048) 0           layer_112[0][0]                  \n",
      "                                                                 layer_110[0][0]                  \n",
      "                                                                 layer_108[0][0]                  \n",
      "                                                                 leaky_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_114 (Conv2D)              (None, 19, 19, 512)  1049088     concat_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_114 (LeakyReLU)           (None, 19, 19, 512)  0           convn_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_115 (Conv2D)              (None, 19, 19, 1024) 4719616     leaky_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_115 (LeakyReLU)           (None, 19, 19, 1024) 0           convn_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_116 (Conv2D)              (None, 19, 19, 512)  524800      leaky_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_116 (LeakyReLU)           (None, 19, 19, 512)  0           convn_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_117 (Conv2D)              (None, 19, 19, 256)  131328      leaky_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_120 (Conv2D)              (None, 38, 38, 256)  131328      convn_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_117 (LeakyReLU)           (None, 19, 19, 256)  0           convn_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_120 (LeakyReLU)           (None, 38, 38, 256)  0           convn_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "upsamp_118 (UpSampling2D)       (None, 38, 38, 256)  0           leaky_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_121 (Concatenate)        (None, 38, 38, 512)  0           leaky_120[0][0]                  \n",
      "                                                                 upsamp_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "convn_122 (Conv2D)              (None, 38, 38, 256)  131328      concat_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_122 (LeakyReLU)           (None, 38, 38, 256)  0           convn_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_123 (Conv2D)              (None, 38, 38, 512)  1180160     leaky_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_123 (LeakyReLU)           (None, 38, 38, 512)  0           convn_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_124 (Conv2D)              (None, 38, 38, 256)  131328      leaky_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_124 (LeakyReLU)           (None, 38, 38, 256)  0           convn_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_125 (Conv2D)              (None, 38, 38, 512)  1180160     leaky_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_125 (LeakyReLU)           (None, 38, 38, 512)  0           convn_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_126 (Conv2D)              (None, 38, 38, 256)  131328      leaky_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_126 (LeakyReLU)           (None, 38, 38, 256)  0           convn_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_127 (Conv2D)              (None, 38, 38, 128)  32896       leaky_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_130 (Conv2D)              (None, 76, 76, 128)  32896       convn_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_127 (LeakyReLU)           (None, 38, 38, 128)  0           convn_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_130 (LeakyReLU)           (None, 76, 76, 128)  0           convn_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "upsamp_128 (UpSampling2D)       (None, 76, 76, 128)  0           leaky_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_131 (Concatenate)        (None, 76, 76, 256)  0           leaky_130[0][0]                  \n",
      "                                                                 upsamp_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "convn_132 (Conv2D)              (None, 76, 76, 128)  32896       concat_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_132 (LeakyReLU)           (None, 76, 76, 128)  0           convn_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_133 (Conv2D)              (None, 76, 76, 256)  295168      leaky_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_133 (LeakyReLU)           (None, 76, 76, 256)  0           convn_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_134 (Conv2D)              (None, 76, 76, 128)  32896       leaky_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_134 (LeakyReLU)           (None, 76, 76, 128)  0           convn_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_135 (Conv2D)              (None, 76, 76, 256)  295168      leaky_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_135 (LeakyReLU)           (None, 76, 76, 256)  0           convn_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_136 (Conv2D)              (None, 76, 76, 128)  32896       leaky_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_136 (LeakyReLU)           (None, 76, 76, 128)  0           convn_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zerop_141 (ZeroPadding2D)       (None, 77, 77, 128)  0           leaky_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_141 (Conv2D)              (None, 38, 38, 256)  295168      zerop_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_141 (LeakyReLU)           (None, 38, 38, 256)  0           convn_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_142 (Concatenate)        (None, 38, 38, 512)  0           leaky_141[0][0]                  \n",
      "                                                                 leaky_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_143 (Conv2D)              (None, 38, 38, 256)  131328      concat_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_143 (LeakyReLU)           (None, 38, 38, 256)  0           convn_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_144 (Conv2D)              (None, 38, 38, 512)  1180160     leaky_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_144 (LeakyReLU)           (None, 38, 38, 512)  0           convn_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_145 (Conv2D)              (None, 38, 38, 256)  131328      leaky_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_145 (LeakyReLU)           (None, 38, 38, 256)  0           convn_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_146 (Conv2D)              (None, 38, 38, 512)  1180160     leaky_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_146 (LeakyReLU)           (None, 38, 38, 512)  0           convn_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_147 (Conv2D)              (None, 38, 38, 256)  131328      leaky_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_147 (LeakyReLU)           (None, 38, 38, 256)  0           convn_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zerop_152 (ZeroPadding2D)       (None, 39, 39, 256)  0           leaky_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_152 (Conv2D)              (None, 19, 19, 512)  1180160     zerop_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_152 (LeakyReLU)           (None, 19, 19, 512)  0           convn_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_153 (Concatenate)        (None, 19, 19, 1024) 0           leaky_152[0][0]                  \n",
      "                                                                 leaky_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_154 (Conv2D)              (None, 19, 19, 512)  524800      concat_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_154 (LeakyReLU)           (None, 19, 19, 512)  0           convn_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_155 (Conv2D)              (None, 19, 19, 1024) 4719616     leaky_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_155 (LeakyReLU)           (None, 19, 19, 1024) 0           convn_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_156 (Conv2D)              (None, 19, 19, 512)  524800      leaky_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_156 (LeakyReLU)           (None, 19, 19, 512)  0           convn_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_157 (Conv2D)              (None, 19, 19, 1024) 4719616     leaky_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_157 (LeakyReLU)           (None, 19, 19, 1024) 0           convn_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_158 (Conv2D)              (None, 19, 19, 512)  524800      leaky_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_158 (LeakyReLU)           (None, 19, 19, 512)  0           convn_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_137 (Conv2D)              (None, 76, 76, 256)  295168      leaky_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_148 (Conv2D)              (None, 38, 38, 512)  1180160     leaky_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_159 (Conv2D)              (None, 19, 19, 1024) 4719616     leaky_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_137 (LeakyReLU)           (None, 76, 76, 256)  0           convn_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_148 (LeakyReLU)           (None, 38, 38, 512)  0           convn_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_159 (LeakyReLU)           (None, 19, 19, 1024) 0           convn_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_138 (Conv2D)              (None, 76, 76, 255)  65535       leaky_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_149 (Conv2D)              (None, 38, 38, 255)  130815      leaky_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convn_160 (Conv2D)              (None, 19, 19, 255)  261375      leaky_159[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,329,949\n",
      "Trainable params: 64,329,949\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0eda63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights in keras\n",
    "from keras.models import Model\n",
    "import struct\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                print(\"reading 64 bytes\")\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                print(\"reading 32 bytes\")\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        count = 0\n",
    "        ncount = 0\n",
    "        for i in range(161):\n",
    "            try:\n",
    "\n",
    "                conv_layer = model.get_layer('convn_' + str(i))\n",
    "                filter = conv_layer.kernel.shape[-1]\n",
    "                nweights = np.prod(conv_layer.kernel.shape) # kernel*kernel*c*filter\n",
    "                \n",
    "                print(\"loading weights of convolution #\" + str(i)+ \"- nb parameters: \"+str(nweights+filter))             \n",
    "                \n",
    "                if i  in [138, 149, 160]:\n",
    "                    print(\"Special Processing for layer \"+ str(i))\n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                \n",
    "                else:                    \n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    scale = self.read_bytes(filter) # scale\n",
    "                    mean  = self.read_bytes(filter) # mean\n",
    "                    var   = self.read_bytes(filter) # variance\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                    \n",
    "                    bias = bias - scale  * mean / (np.sqrt(var + 0.00001)) #normalize bias\n",
    "\n",
    "                    weights = np.reshape(weights,(filter,int(nweights/filter)))  #normalize weights\n",
    "                    A = scale / (np.sqrt(var + 0.00001))\n",
    "                    A= np.expand_dims(A,axis=0)\n",
    "                    weights = weights* A.T\n",
    "                    weights = np.reshape(weights,(nweights))\n",
    "                \n",
    "\n",
    "                weights = weights.reshape(list(reversed(conv_layer.get_weights()[0].shape)))                 \n",
    "                weights = weights.transpose([2,3,1,0])\n",
    "                \n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    a=conv_layer.set_weights([weights, bias])\n",
    "                else:    \n",
    "                    a=conv_layer.set_weights([weights])\n",
    "                \n",
    "                count = count+1\n",
    "                ncount = ncount+nweights+filter\n",
    "             \n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i)) \n",
    "        \n",
    "        print(count, \"Convolution Normalized Layers are loaded with \", ncount, \" parameters\")\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "905c192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 64 bytes\n",
      "loading weights of convolution #0- nb parameters: 896\n",
      "loading weights of convolution #1- nb parameters: 18496\n",
      "loading weights of convolution #2- nb parameters: 4160\n",
      "no convolution #3\n",
      "loading weights of convolution #4- nb parameters: 4160\n",
      "loading weights of convolution #5- nb parameters: 2080\n",
      "loading weights of convolution #6- nb parameters: 18496\n",
      "no convolution #7\n",
      "loading weights of convolution #8- nb parameters: 4160\n",
      "no convolution #9\n",
      "loading weights of convolution #10- nb parameters: 8256\n",
      "loading weights of convolution #11- nb parameters: 73856\n",
      "loading weights of convolution #12- nb parameters: 8256\n",
      "no convolution #13\n",
      "loading weights of convolution #14- nb parameters: 8256\n",
      "loading weights of convolution #15- nb parameters: 4160\n",
      "loading weights of convolution #16- nb parameters: 36928\n",
      "no convolution #17\n",
      "loading weights of convolution #18- nb parameters: 4160\n",
      "loading weights of convolution #19- nb parameters: 36928\n",
      "no convolution #20\n",
      "loading weights of convolution #21- nb parameters: 4160\n",
      "no convolution #22\n",
      "loading weights of convolution #23- nb parameters: 16512\n",
      "loading weights of convolution #24- nb parameters: 295168\n",
      "loading weights of convolution #25- nb parameters: 32896\n",
      "no convolution #26\n",
      "loading weights of convolution #27- nb parameters: 32896\n",
      "loading weights of convolution #28- nb parameters: 16512\n",
      "loading weights of convolution #29- nb parameters: 147584\n",
      "no convolution #30\n",
      "loading weights of convolution #31- nb parameters: 16512\n",
      "loading weights of convolution #32- nb parameters: 147584\n",
      "no convolution #33\n",
      "loading weights of convolution #34- nb parameters: 16512\n",
      "loading weights of convolution #35- nb parameters: 147584\n",
      "no convolution #36\n",
      "loading weights of convolution #37- nb parameters: 16512\n",
      "loading weights of convolution #38- nb parameters: 147584\n",
      "no convolution #39\n",
      "loading weights of convolution #40- nb parameters: 16512\n",
      "loading weights of convolution #41- nb parameters: 147584\n",
      "no convolution #42\n",
      "loading weights of convolution #43- nb parameters: 16512\n",
      "loading weights of convolution #44- nb parameters: 147584\n",
      "no convolution #45\n",
      "loading weights of convolution #46- nb parameters: 16512\n",
      "loading weights of convolution #47- nb parameters: 147584\n",
      "no convolution #48\n",
      "loading weights of convolution #49- nb parameters: 16512\n",
      "loading weights of convolution #50- nb parameters: 147584\n",
      "no convolution #51\n",
      "loading weights of convolution #52- nb parameters: 16512\n",
      "no convolution #53\n",
      "loading weights of convolution #54- nb parameters: 65792\n",
      "loading weights of convolution #55- nb parameters: 1180160\n",
      "loading weights of convolution #56- nb parameters: 131328\n",
      "no convolution #57\n",
      "loading weights of convolution #58- nb parameters: 131328\n",
      "loading weights of convolution #59- nb parameters: 65792\n",
      "loading weights of convolution #60- nb parameters: 590080\n",
      "no convolution #61\n",
      "loading weights of convolution #62- nb parameters: 65792\n",
      "loading weights of convolution #63- nb parameters: 590080\n",
      "no convolution #64\n",
      "loading weights of convolution #65- nb parameters: 65792\n",
      "loading weights of convolution #66- nb parameters: 590080\n",
      "no convolution #67\n",
      "loading weights of convolution #68- nb parameters: 65792\n",
      "loading weights of convolution #69- nb parameters: 590080\n",
      "no convolution #70\n",
      "loading weights of convolution #71- nb parameters: 65792\n",
      "loading weights of convolution #72- nb parameters: 590080\n",
      "no convolution #73\n",
      "loading weights of convolution #74- nb parameters: 65792\n",
      "loading weights of convolution #75- nb parameters: 590080\n",
      "no convolution #76\n",
      "loading weights of convolution #77- nb parameters: 65792\n",
      "loading weights of convolution #78- nb parameters: 590080\n",
      "no convolution #79\n",
      "loading weights of convolution #80- nb parameters: 65792\n",
      "loading weights of convolution #81- nb parameters: 590080\n",
      "no convolution #82\n",
      "loading weights of convolution #83- nb parameters: 65792\n",
      "no convolution #84\n",
      "loading weights of convolution #85- nb parameters: 262656\n",
      "loading weights of convolution #86- nb parameters: 4719616\n",
      "loading weights of convolution #87- nb parameters: 524800\n",
      "no convolution #88\n",
      "loading weights of convolution #89- nb parameters: 524800\n",
      "loading weights of convolution #90- nb parameters: 262656\n",
      "loading weights of convolution #91- nb parameters: 2359808\n",
      "no convolution #92\n",
      "loading weights of convolution #93- nb parameters: 262656\n",
      "loading weights of convolution #94- nb parameters: 2359808\n",
      "no convolution #95\n",
      "loading weights of convolution #96- nb parameters: 262656\n",
      "loading weights of convolution #97- nb parameters: 2359808\n",
      "no convolution #98\n",
      "loading weights of convolution #99- nb parameters: 262656\n",
      "loading weights of convolution #100- nb parameters: 2359808\n",
      "no convolution #101\n",
      "loading weights of convolution #102- nb parameters: 262656\n",
      "no convolution #103\n",
      "loading weights of convolution #104- nb parameters: 1049600\n",
      "loading weights of convolution #105- nb parameters: 524800\n",
      "loading weights of convolution #106- nb parameters: 4719616\n",
      "loading weights of convolution #107- nb parameters: 524800\n",
      "no convolution #108\n",
      "no convolution #109\n",
      "no convolution #110\n",
      "no convolution #111\n",
      "no convolution #112\n",
      "no convolution #113\n",
      "loading weights of convolution #114- nb parameters: 1049088\n",
      "loading weights of convolution #115- nb parameters: 4719616\n",
      "loading weights of convolution #116- nb parameters: 524800\n",
      "loading weights of convolution #117- nb parameters: 131328\n",
      "no convolution #118\n",
      "no convolution #119\n",
      "loading weights of convolution #120- nb parameters: 131328\n",
      "no convolution #121\n",
      "loading weights of convolution #122- nb parameters: 131328\n",
      "loading weights of convolution #123- nb parameters: 1180160\n",
      "loading weights of convolution #124- nb parameters: 131328\n",
      "loading weights of convolution #125- nb parameters: 1180160\n",
      "loading weights of convolution #126- nb parameters: 131328\n",
      "loading weights of convolution #127- nb parameters: 32896\n",
      "no convolution #128\n",
      "no convolution #129\n",
      "loading weights of convolution #130- nb parameters: 32896\n",
      "no convolution #131\n",
      "loading weights of convolution #132- nb parameters: 32896\n",
      "loading weights of convolution #133- nb parameters: 295168\n",
      "loading weights of convolution #134- nb parameters: 32896\n",
      "loading weights of convolution #135- nb parameters: 295168\n",
      "loading weights of convolution #136- nb parameters: 32896\n",
      "loading weights of convolution #137- nb parameters: 295168\n",
      "loading weights of convolution #138- nb parameters: 65535\n",
      "Special Processing for layer 138\n",
      "no convolution #139\n",
      "no convolution #140\n",
      "loading weights of convolution #141- nb parameters: 295168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-37709dc4798b>:54: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bias = bias - scale  * mean / (np.sqrt(var + 0.00001)) #normalize bias\n",
      "<ipython-input-21-37709dc4798b>:57: RuntimeWarning: invalid value encountered in sqrt\n",
      "  A = scale / (np.sqrt(var + 0.00001))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no convolution #142\n",
      "loading weights of convolution #143- nb parameters: 131328\n",
      "loading weights of convolution #144- nb parameters: 1180160\n",
      "loading weights of convolution #145- nb parameters: 131328\n",
      "loading weights of convolution #146- nb parameters: 1180160\n",
      "loading weights of convolution #147- nb parameters: 131328\n",
      "loading weights of convolution #148- nb parameters: 1180160\n",
      "loading weights of convolution #149- nb parameters: 130815\n",
      "Special Processing for layer 149\n",
      "no convolution #150\n",
      "no convolution #151\n",
      "loading weights of convolution #152- nb parameters: 1180160\n",
      "no convolution #153\n",
      "loading weights of convolution #154- nb parameters: 524800\n",
      "loading weights of convolution #155- nb parameters: 4719616\n",
      "loading weights of convolution #156- nb parameters: 524800\n",
      "loading weights of convolution #157- nb parameters: 4719616\n",
      "loading weights of convolution #158- nb parameters: 524800\n",
      "loading weights of convolution #159- nb parameters: 4719616\n",
      "no convolution #159\n",
      "loading weights of convolution #160- nb parameters: 261375\n",
      "Special Processing for layer 160\n",
      "no convolution #160\n",
      "108 Convolution Normalized Layers are loaded with  59348958  parameters\n"
     ]
    }
   ],
   "source": [
    "# Load and Compute the YOLOv4 weights\n",
    "weight_reader = WeightReader('yolov4-bees_final.weights')\n",
    "weight_reader.load_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf69c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
